{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14dbfd3-f967-439c-b158-7e19b9bafbc4",
   "metadata": {},
   "source": [
    "## Sensitivity Analysis\n",
    "- DAS Article Suggestions\n",
    "- 25-Dec-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ee21e98-27ae-48ee-8332-e45cbcbbb42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " == REINFORCE for Predictive Maintenance ==\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "* Experiments file: SA_test.csv -- Rounds 1\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "START_ROUND = 0\n",
    "TRAINING_ROUNDS = 1\n",
    "# EXPTS_SETTINGS = 'SensitivityAnalysis.csv'\n",
    "EXPTS_SETTINGS = 'SA_test.csv'\n",
    "MIN_MODEL_PERFORMANCE = -1.0 # Set to 0.70, to auto save models with metrics > 0.7\n",
    "\n",
    "print ('\\n == REINFORCE for Predictive Maintenance ==')\n",
    "print (120*'-')\n",
    "print (f'* Experiments file: {EXPTS_SETTINGS} -- Rounds {TRAINING_ROUNDS}')\n",
    "print (120*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3067e0ed-9843-47eb-8b71-215ff661b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sensitivity Analysis: LR: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Policy network learning parameters\n",
    "gamma = 0.99\n",
    "\n",
    "learning_rates = [1e-2, 0.5e-2, 1e-3]\n",
    "alpha = learning_rates[0]  # Learning rate\n",
    "\n",
    "print (f'\\n Sensitivity Analysis: LR: {alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23994053-ed36-4ad9-b558-99c78d41bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading packages...\n"
     ]
    }
   ],
   "source": [
    "print ('- Loading packages...')\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3 import A2C, PPO, DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "from milling_tool_environment import MillingTool_SS_NT, MillingTool_MS_V3\n",
    "from utilities import compute_metrics, compute_metrics_simple, write_metrics_report, store_results, plot_learning_curve, single_axes_plot, lnoise\n",
    "from utilities import two_axes_plot, two_variable_plot, plot_error_bounds, test_script, write_test_results, downsample, save_model, load_model, clean_up_files\n",
    "from utilities import add_performance_columns, summary_performance_metrics\n",
    "from reinforce_classes import PolicyNetwork, Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb8cee1a-4368-4a74-88d4-129d87f245eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_summary = []\n",
    "n_tr_round = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21fc0c57-a7a6-41fd-b4cd-a0a09dfab340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Loading Experiments...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auto experiment file structure\n",
    "print ('- Loading Experiments...')\n",
    "df_expts = pd.read_csv(EXPTS_SETTINGS)\n",
    "\n",
    "# Add round number column to Experiments files\n",
    "df_expts['Round'] = n_tr_round\n",
    "# Initialize columns for recording model performance\n",
    "df_expts = add_performance_columns(df_expts)\n",
    "df_expts['model_file'] = 'Not satisfactory'\n",
    "\n",
    "# Initialize record training time\n",
    "df_expts['RF_time'] = 0.0\n",
    "df_expts['A2C_time'] = 0.0\n",
    "df_expts['DQN_time'] = 0.0\n",
    "df_expts['PPO_time'] = 0.0\n",
    "\n",
    "n_expts = len(df_expts.index)\n",
    "n_expt = 0\n",
    "n_expt, n_expts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c50949f-0c79-465d-b352-b03155e13412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "************************************************************************************************************************\n",
      "************************************************************************************************************************\n",
      " * Round-0 Experiment 0 | PHM_C01_SS_NoNBD\n",
      "========================================================================================================================\n",
      "\n",
      "- Columns added to results file:  results//0_0_PHM_C01_SS_NoNBD__test_results_25-Dec-2024_11-49.csv\n"
     ]
    }
   ],
   "source": [
    "dt = datetime.now()\n",
    "dt_d = dt.strftime('%d-%b-%Y')\n",
    "dt_t = dt.strftime('%H-%M')\n",
    "dt_m = f'{dt_d}_{dt_t}'\n",
    "# dt_m = dt.strftime('%d-%H%M')\n",
    "\n",
    "# Load experiment parameters\n",
    "ENVIRONMENT_CLASS = df_expts['environment'][n_expt]\n",
    "ENVIRONMENT_INFO = df_expts['environment_info'][n_expt]\n",
    "ENVIRONMENT_INFO = f'{ENVIRONMENT_INFO}-{ENVIRONMENT_CLASS}'\n",
    "DATA_FILE = df_expts['data_file'][n_expt]\n",
    "R1 = df_expts['R1'][n_expt]\n",
    "R2 = df_expts['R2'][n_expt]\n",
    "R3 = df_expts['R3'][n_expt]\n",
    "WEAR_THRESHOLD = df_expts['wear_threshold'][n_expt]\n",
    "THRESHOLD_FACTOR = df_expts['threshold_factor'][n_expt]\n",
    "ADD_NOISE = df_expts['add_noise'][n_expt]\n",
    "BREAKDOWN_CHANCE = df_expts['breakdown_chance'][n_expt]\n",
    "EPISODES = df_expts['episodes'][n_expt]\n",
    "MILLING_OPERATIONS_MAX = df_expts['milling_operations_max'][n_expt]\n",
    "ver_prefix = df_expts['version_prefix'][n_expt]\n",
    "TEST_INFO = df_expts['test_info'][n_expt]\n",
    "TEST_CASES = df_expts['test_cases'][n_expt]\n",
    "TEST_ROUNDS = df_expts['test_rounds'][n_expt]\n",
    "RESULTS_FOLDER = df_expts['results_folder'][n_expt]\n",
    "\n",
    "TEST_FILE = df_expts['test_file'][n_expt]\n",
    "TRAIN_SR = df_expts['train_sample_rate'][n_expt]\n",
    "TEST_SR = df_expts['test_sample_rate'][n_expt]\n",
    "\n",
    "## Read data\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "n_records = len(df.index)\n",
    "l_noise = lnoise(ADD_NOISE, BREAKDOWN_CHANCE)\n",
    "#VERSION = f'{ver_prefix}_{l_noise}_{WEAR_THRESHOLD}_{THRESHOLD_FACTOR}_{R3}_{EPISODES}_{MILLING_OPERATIONS_MAX}_'\n",
    "VERSION = f'{n_tr_round}_{n_expt}_{ver_prefix}_{l_noise}_'\n",
    "print('\\n\\n')\n",
    "print(120*'*')\n",
    "print(120*'*')\n",
    "print(f' * Round-{n_tr_round} Experiment {n_expt} | {ver_prefix}_{l_noise}')\n",
    "print(120*'=')\n",
    "\n",
    "METRICS_METHOD = 'binary' # average method = {‘micro’, ‘macro’, ‘samples’, ‘weighted’, ‘binary’}\n",
    "WEAR_THRESHOLD_NORMALIZED = 0.0 # normalized to the max wear threshold\n",
    "\n",
    "CONSOLIDATED_METRICS_FILE = f'{RESULTS_FOLDER}/TEST_CONSOLIDATED_METRICS.csv'\n",
    "RESULTS_FILE = f'{RESULTS_FOLDER}/{VERSION}_test_results_{dt_m}.csv'\n",
    "METRICS_FILE = f'{RESULTS_FOLDER}/{VERSION}_metrics.csv'\n",
    "END_ROUND = START_ROUND + TRAINING_ROUNDS\n",
    "EXPTS_REPORT = f'{RESULTS_FOLDER}/Experiment_Results_{START_ROUND}_{END_ROUND}_{n_tr_round}.csv'\n",
    "\n",
    "logdir = './tensorboard/'\n",
    "\n",
    "print('\\n- Columns added to results file: ', RESULTS_FILE)\n",
    "results = ['Date', 'Time', 'Round', 'Environment', 'Training_data', 'Wear_Threshold', 'Test_data', 'Algorithm', 'Episodes', 'Normal_cases', 'Normal_error',\n",
    "           'Replace_cases', 'Replace_error', 'Overall_error',\n",
    "           'Precision', 'Recall', 'F_Beta_0_5', 'F_Beta_0_75', 'F_1_Score']\n",
    "write_test_results(results, RESULTS_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79689c7d-e60a-4108-8c8b-89a550bb87a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tool wear data imported (34722 records).\n"
     ]
    }
   ],
   "source": [
    "# 1. Add noise\n",
    "if ADD_NOISE:\n",
    "    df['tool_wear'] += np.random.normal(0, 1, n_records)/ADD_NOISE\n",
    "\n",
    "# 2. Add ACTION code\n",
    "df['ACTION_CODE'] = np.where(df['tool_wear'] < WEAR_THRESHOLD, 0.0, 1.0)\n",
    "\n",
    "# 3. Normalize\n",
    "WEAR_MIN = df['tool_wear'].min()\n",
    "WEAR_MAX = df['tool_wear'].max()\n",
    "WEAR_THRESHOLD_ORG_NORMALIZED = (WEAR_THRESHOLD-WEAR_MIN)/(WEAR_MAX-WEAR_MIN)\n",
    "WEAR_THRESHOLD_NORMALIZED = THRESHOLD_FACTOR*(WEAR_THRESHOLD-WEAR_MIN)/(WEAR_MAX-WEAR_MIN)\n",
    "df_normalized = (df-df.min())/(df.max()-df.min())\n",
    "df_normalized['ACTION_CODE'] = df['ACTION_CODE']\n",
    "print(f'- Tool wear data imported ({len(df.index)} records).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "622846a6-9278-4074-b7f2-29f7bc831d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Down-sampling. Input data records: 34722. Sampling rate: 100. Expected rows 347. Down-sampled to 348 rows.\n",
      "- Down-sampling. Input data records: 34722. Sampling rate: 70. Expected rows 496. Down-sampled to 497 rows.\n",
      "- Tool wear data split into train (348 records) and test (497 records).\n"
     ]
    }
   ],
   "source": [
    "# 4. Test file -or- create test file\n",
    "if TRAIN_SR:\n",
    "    # 4. Split into train and test\n",
    "    df_train = downsample(df_normalized, TRAIN_SR)\n",
    "    df_train.to_csv('TempTrain.csv')\n",
    "    df_train = pd.read_csv('TempTrain.csv')\n",
    "\n",
    "    df_test = downsample(df_normalized, TEST_SR)\n",
    "    df_test.to_csv('TempTest.csv')\n",
    "    df_test = pd.read_csv('TempTest.csv')\n",
    "    print(f'- Tool wear data split into train ({len(df_train.index)} records) and test ({len(df_test.index)} records).')\n",
    "else:\n",
    "    # 4. Split into train and test\n",
    "    df_train = df_normalized\n",
    "    df_test = pd.read_csv(TEST_FILE)\n",
    "    print(f'* Separate test data provided: {TEST_FILE} - ({len(df_test.index)} records).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "910212c4-95e0-48ce-93f6-2d3b5adee9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_records = len(df_train.index)\n",
    "x = [n for n in range(n_records)]\n",
    "y1 = df_train['tool_wear']\n",
    "y2 = df_train['ACTION_CODE']\n",
    "wear_plot = f'{RESULTS_FOLDER}/{VERSION}_wear_plot.png'\n",
    "title=f'Tool Wear (mm) data\\n{VERSION}'\n",
    "two_axes_plot(x, y1, y2, title=title, x_label='Time', y1_label='Tool Wear (mm)', y2_label='Action code (1=Replace)', xticks=20, file=wear_plot, threshold_org = WEAR_THRESHOLD_ORG_NORMALIZED, threshold=WEAR_THRESHOLD_NORMALIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1606c87d-f512-437e-b635-1e8f4f54f5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAS RUN\n",
      "\n",
      "\n",
      "** -- Single-variate env. wear_threshold: 0.5170 R1: 1, R2: -1, R3: -40. Noise: 0. Break-down chance: 0 -- **\n",
      "DAS RUN\n",
      "\n",
      "\n",
      "** -- Single-variate env. wear_threshold: 0.5744 R1: 1, R2: -1, R3: -40. Noise: 0. Break-down chance: 0 -- **\n"
     ]
    }
   ],
   "source": [
    "if ENVIRONMENT_CLASS == 'SS':\n",
    "    env = MillingTool_SS_NT(df_train, WEAR_THRESHOLD_NORMALIZED, MILLING_OPERATIONS_MAX, ADD_NOISE, BREAKDOWN_CHANCE, R1, R2, R3)\n",
    "    env_test = MillingTool_SS_NT(df_test, WEAR_THRESHOLD_ORG_NORMALIZED, MILLING_OPERATIONS_MAX, ADD_NOISE, BREAKDOWN_CHANCE, R1, R2, R3)\n",
    "elif ENVIRONMENT_CLASS == 'MS':\n",
    "    env = MillingTool_MS_V3(df_train, WEAR_THRESHOLD_NORMALIZED, MILLING_OPERATIONS_MAX, ADD_NOISE, BREAKDOWN_CHANCE, R1, R2, R3)\n",
    "    env_test = MillingTool_MS_V3(df_test, WEAR_THRESHOLD_ORG_NORMALIZED, MILLING_OPERATIONS_MAX, ADD_NOISE, BREAKDOWN_CHANCE, R1, R2, R3)\n",
    "else:\n",
    "    print(' ERROR - initatizing environment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "447931e7-33fb-47ae-8c0e-0a92413a9bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Train REINFORCE model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable tensorboard rewards and loss plots\n",
    "# env = Monitor(env, logdir, allow_early_resets=True)\n",
    "# print('----NO MONITOR----')\n",
    "\n",
    "# ## REINFORCE RL Algorithm\n",
    "### Main loop\n",
    "print('\\n* Train REINFORCE model...')\n",
    "rewards_history = []\n",
    "loss_history = []\n",
    "training_stats = []\n",
    "\n",
    "input_dim = env.observation_space.shape[0]\n",
    "output_dim = env.action_space.n\n",
    "\n",
    "agent_RF = Agent(input_dim, output_dim, alpha, gamma)\n",
    "\n",
    "EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4339df8c-1586-417c-94b2-6361195628b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0000] Loss:  -1.37e-03 | Reward:  -5.60e-04 | Ep.length: 0005\n"
     ]
    }
   ],
   "source": [
    "# $$$ \n",
    "truncated = False\n",
    "\n",
    "time_RF = time.time()\n",
    "for episode in range(EPISODES):\n",
    "    state = env.reset()\n",
    "\n",
    "    # Sample a trajectory\n",
    "    for t in range(MILLING_OPERATIONS_MAX): # Max. milling operations desired\n",
    "        action = agent_RF.act(state)\n",
    "        # state, reward, done, truncated, info = env.step(action)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        agent_RF.rewards.append(reward)\n",
    "        #env.render()\n",
    "        if done:\n",
    "            # print('** DONE **', info)\n",
    "            break\n",
    "\n",
    "    # Learn during this episode\n",
    "    loss = agent_RF.learn() # train per episode\n",
    "    total_reward = sum(agent_RF.rewards)\n",
    "\n",
    "    # Record statistics for this episode\n",
    "    rewards_history.append(total_reward)\n",
    "    loss_history.append(loss.item()) # Extract values from list of torch items for plotting\n",
    "\n",
    "    # On-policy - so discard all data\n",
    "    agent_RF.onpolicy_reset()\n",
    "\n",
    "    if (episode%100 == 0):\n",
    "        # print(f'[{episode:04d}] Loss: {loss:>10.2f} | Reward: {total_reward:>10.2f} | Ep.length: {env.ep_length:04d}')\n",
    "        print(f'[{episode:04d}] Loss: {loss:>10.2e} | Reward: {total_reward:>10.2e} | Ep.length: {env.ep_length:04d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6b947af-5f07-49d3-90da-6a12d1961e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end RF training\n",
    "time_RF = time.time() - time_RF\n",
    "\n",
    "x = [i for i in range(EPISODES)]\n",
    "\n",
    "# ## Moving average for rewards\n",
    "ma_window_size = 10\n",
    "# # Convert error array to pandas series\n",
    "rewards = pd.Series(rewards_history)\n",
    "windows = rewards.rolling(ma_window_size)\n",
    "moving_avg = windows.mean()\n",
    "moving_avg_lst = moving_avg.tolist()\n",
    "y1 = rewards\n",
    "y2 = moving_avg_lst\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Avg_episode_rewards.png'\n",
    "two_variable_plot(x, y1, y2, 'Avg. rewards per episode', VERSION, 'Episode', 'Avg. Rewards', 'Moving Avg.', 50, filename)\n",
    "\n",
    "# plot_error_bounds(x, y1)\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Episode_Length.png'\n",
    "single_axes_plot(x, env.ep_length_history, 'Episode length', VERSION, 'Episode', 'No of milling operations', 50, 0.0, filename)\n",
    "\n",
    "filename = f'{RESULTS_FOLDER}/{VERSION}_Tool_Replacements.png'\n",
    "single_axes_plot(x, env.ep_tool_replaced_history, 'Tool replacements per episode', VERSION, 'Episode', 'Replacements', 50, 0.0, filename)\n",
    "\n",
    "# ### Generate a balanced test set\n",
    "idx_replace_cases = df_test.index[df_test['ACTION_CODE'] >= 1.0]\n",
    "idx_normal_cases = df_test.index[df_test['ACTION_CODE'] < 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a41b9519-b4de-462f-ad14-2f9878204a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Test REINFORCE model...\n",
      "***** SB-3 TEST CASES: 0 -- [157, 78, 116, 189, 99, 144, 169, 166, 235, 22, 69, 250, 118, 115, 49, 160, 230, 212, 252, 251, 377, 355, 453, 357, 426, 491, 429, 456, 402, 315, 475, 412, 420, 390, 401, 462, 492, 443, 432, 364]\n",
      "***** SB-3 TEST CASES: 1 -- [160, 78, 250, 251, 99, 144, 252, 49, 230, 212, 22, 157, 169, 116, 69, 235, 189, 118, 115, 166, 412, 355, 390, 420, 377, 475, 315, 357, 462, 456, 443, 492, 491, 364, 453, 429, 426, 402, 432, 401]\n",
      "***** SB-3 TEST CASES: 2 -- [69, 166, 22, 115, 235, 252, 160, 230, 99, 212, 251, 49, 144, 169, 157, 78, 116, 118, 250, 189, 462, 377, 355, 453, 390, 401, 426, 412, 492, 456, 364, 443, 491, 432, 420, 475, 357, 429, 315, 402]\n",
      "***** SB-3 TEST CASES: 3 -- [69, 99, 235, 22, 49, 212, 144, 251, 169, 189, 115, 252, 78, 116, 166, 160, 250, 118, 230, 157, 453, 412, 402, 475, 492, 357, 456, 390, 355, 426, 491, 429, 462, 432, 315, 420, 364, 443, 377, 401]\n",
      "***** SB-3 TEST CASES: 4 -- [251, 49, 252, 78, 69, 189, 118, 230, 250, 212, 166, 115, 235, 99, 116, 169, 160, 157, 144, 22, 492, 453, 456, 377, 315, 402, 491, 462, 412, 475, 355, 443, 429, 426, 420, 390, 357, 364, 401, 432]\n",
      "***** SB-3 TEST CASES: 5 -- [212, 160, 118, 251, 166, 250, 252, 99, 22, 157, 169, 235, 116, 144, 49, 78, 189, 230, 69, 115, 491, 377, 475, 453, 462, 420, 432, 402, 412, 401, 357, 390, 364, 315, 492, 355, 456, 426, 429, 443]\n",
      "***** SB-3 TEST CASES: 6 -- [250, 169, 251, 99, 118, 235, 160, 69, 212, 252, 157, 166, 230, 115, 144, 49, 22, 189, 116, 78, 429, 401, 390, 355, 456, 315, 377, 432, 491, 492, 453, 443, 364, 462, 357, 426, 412, 420, 402, 475]\n",
      "***** SB-3 TEST CASES: 7 -- [99, 69, 157, 144, 169, 230, 166, 235, 212, 118, 250, 49, 251, 22, 252, 115, 160, 189, 116, 78, 420, 491, 475, 462, 315, 401, 456, 364, 432, 355, 443, 453, 426, 492, 402, 377, 357, 390, 412, 429]\n",
      "***** SB-3 TEST CASES: 8 -- [115, 157, 252, 22, 49, 144, 189, 166, 212, 116, 235, 160, 78, 118, 99, 251, 230, 169, 250, 69, 492, 432, 390, 475, 402, 420, 364, 355, 491, 412, 453, 456, 401, 315, 357, 462, 443, 426, 377, 429]\n",
      "***** SB-3 TEST CASES: 9 -- [99, 252, 250, 144, 212, 118, 69, 251, 166, 116, 22, 230, 235, 160, 78, 189, 169, 49, 115, 157, 315, 453, 429, 432, 475, 426, 443, 492, 462, 357, 401, 456, 412, 364, 377, 491, 355, 390, 420, 402]\n",
      "*\n",
      "========================================================================================================================\n",
      "[0:0] >> PHM C01 SS NBD-SS - NoNBD Pr: 0.390 \t Rc: 0.060 \t F1:0.181\n",
      "========================================================================================================================\n",
      "*\n",
      "- REINFORCE Test results written to file: results//0_0_PHM_C01_SS_NoNBD__test_results_25-Dec-2024_11-49.csv.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process results\n",
    "# eps = [i for i in range(EPISODES)]\n",
    "# store_results(RF_TRAINING_FILE, training_round, eps, rewards_history, env.ep_tool_replaced_history)\n",
    "print('\\n- Test REINFORCE model...')\n",
    "# print(80*'-')\n",
    "# print(f'Algorithm\\tNormal\\terr.%\\tReplace\\terr.%\\tOverall err.%')\n",
    "# print(80*'-')\n",
    "avg_Pr = avg_Rc = avg_F1 = 0.0\n",
    "\n",
    "test_case_collection = []\n",
    "for test_round in range(TEST_ROUNDS):\n",
    "    # Create test cases\n",
    "    idx_replace_cases = np.random.choice(idx_replace_cases, int(TEST_CASES/2), replace=False)\n",
    "    idx_normal_cases = np.random.choice(idx_normal_cases, int(TEST_CASES/2), replace=False)\n",
    "    test_cases = [*idx_normal_cases, *idx_replace_cases]\n",
    "    test_case_collection.append(test_cases)\n",
    "    print(f'***** SB-3 TEST CASES: {test_round} -- {test_case_collection[test_round]}')\n",
    "\n",
    "    results = test_script(METRICS_METHOD, test_round, df_test, 'REINFORCE', EPISODES, env_test, ENVIRONMENT_INFO, agent_RF,\n",
    "                          test_cases, TEST_INFO, DATA_FILE, WEAR_THRESHOLD, RESULTS_FILE)\n",
    "    write_test_results(results, RESULTS_FILE)\n",
    "    avg_Pr += results[14]\n",
    "    avg_Rc += results[15]\n",
    "    avg_F1 += results[16]\n",
    "\n",
    "avg_Pr = avg_Pr/TEST_ROUNDS\n",
    "avg_Rc = avg_Rc/TEST_ROUNDS\n",
    "avg_F1 = avg_F1/TEST_ROUNDS\n",
    "\n",
    "# df_expts.loc[n_expt, 'Pr'] = avg_Pr\n",
    "# df_expts.loc[n_expt, 'Rc'] = avg_Rc\n",
    "# df_expts.loc[n_expt, 'F1'] = avg_F1\n",
    "\n",
    "df_expts.loc[n_expt, 'RF_time'] = time_RF\n",
    "\n",
    "expt_summary = f'[{n_tr_round}:{n_expt}] >> {ENVIRONMENT_INFO} - {l_noise} Pr: {avg_Pr:0.3f} \\t Rc: {avg_Rc:0.3f} \\t F1:{avg_F1:0.3f}'\n",
    "experiment_summary.append(expt_summary)\n",
    "print('*')\n",
    "print(120*'=')\n",
    "print(expt_summary)\n",
    "print(120*'=')\n",
    "print('*')\n",
    "\n",
    "print(f'- REINFORCE Test results written to file: {RESULTS_FILE}.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdc69a-d2e3-48a9-bb44-f171d40b163a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e69e254-d356-41e7-9f29-b5b8c42721a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** REINFORCE model performance satisfactory. Saving model to models/0_0_PHM_C01_SS_NoNBD__RF_Model_25-Dec-2024_11-49_0.39_0.06_0.18.mdl ***\n",
      "\n",
      "* Model saved to models/0_0_PHM_C01_SS_NoNBD__RF_Model_25-Dec-2024_11-49_0.39_0.06_0.18.mdl.\n",
      "* Test Report: Algorithm level consolidated metrics will be written to: results//0_0_PHM_C01_SS_NoNBD__metrics.csv.\n",
      "- Experiment related meta info written.\n",
      "- Algorithm level consolidated metrics reported to file.\n",
      "- results//TEST_CONSOLIDATED_METRICS.csv file updated.\n",
      "          Precision        Recall        F_Beta_0_5        F_Beta_0_75         \\\n",
      "               mean    std   mean    std       mean    std        mean    std   \n",
      "Algorithm                                                                       \n",
      "REINFORCE      0.39  0.252   0.06  0.046      0.181  0.127       0.128  0.094   \n",
      "\n",
      "          F_1_Score        Normal_error Replace_error Overall_error  \n",
      "               mean    std         mean          mean          mean  \n",
      "Algorithm                                                            \n",
      "REINFORCE     0.103  0.076         0.09          0.94         0.515  \n",
      "- Updating summary performance metrics.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'A2C'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'A2C'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# $$$ Update\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- Updating summary performance metrics.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m     \u001b[43msummary_performance_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_expts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_expt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m- End Experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_tr_round\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_expt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\ResearchLab\\Empirical_Study_REINFORCE\\code\\utilities.py:102\u001b[0m, in \u001b[0;36msummary_performance_metrics\u001b[1;34m(df_expts, n_expt, algo_metrics)\u001b[0m\n\u001b[0;32m     99\u001b[0m df_expts\u001b[38;5;241m.\u001b[39mloc[n_expt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF_F05\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m algo_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF_Beta_0_5\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREINFORCE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    100\u001b[0m df_expts\u001b[38;5;241m.\u001b[39mloc[n_expt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRF_F05_sd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m algo_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF_Beta_0_5\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREINFORCE\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m df_expts\u001b[38;5;241m.\u001b[39mloc[n_expt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C_Pr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43malgo_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA2C\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    103\u001b[0m df_expts\u001b[38;5;241m.\u001b[39mloc[n_expt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C_Pr_sd\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m algo_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    104\u001b[0m df_expts\u001b[38;5;241m.\u001b[39mloc[n_expt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C_Rc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m algo_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRecall\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\RL\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'A2C'"
     ]
    }
   ],
   "source": [
    "### Create a consolidated algorithm wise metrics summary\n",
    "## Add model training hyper parameters and save model, if metrics > 0.65\n",
    "if avg_Pr > MIN_MODEL_PERFORMANCE and avg_Rc > MIN_MODEL_PERFORMANCE and avg_F1 > MIN_MODEL_PERFORMANCE:\n",
    "    model_file_RF = f'models/{VERSION}_RF_Model_{dt_m}_{avg_Pr:.2f}_{avg_Rc:.2f}_{avg_F1:.2f}.mdl'\n",
    "    print(f'\\n*** REINFORCE model performance satisfactory. Saving model to {model_file_RF} ***\\n')\n",
    "\n",
    "    agent_RF.model_parameters = {'R1':R1, 'R2':R2, 'R3':R3, 'WEAR_THRESHOLD':WEAR_THRESHOLD, 'THRESHOLD_FACTOR':THRESHOLD_FACTOR, 'ADD_NOISE':ADD_NOISE, 'BREAKDOWN_CHANCE':BREAKDOWN_CHANCE, 'EPISODES':EPISODES, 'MILLING_OPERATIONS_MAX':MILLING_OPERATIONS_MAX}\n",
    "    save_model(agent_RF, model_file_RF)\n",
    "    df_expts.loc[n_expt, 'model_file'] = model_file_RF\n",
    "    \n",
    "    print(f'* Test Report: Algorithm level consolidated metrics will be written to: {METRICS_FILE}.')\n",
    "\n",
    "    header_columns = [VERSION]\n",
    "    write_test_results(header_columns, METRICS_FILE)\n",
    "    header_columns = ['Date', 'Time', 'Environment', 'Noise', 'Breakdown_chance', 'Train_data', 'env.R1', 'env.R2', 'env.R3', 'Wear threshold', 'Look-ahead Factor', 'Episodes', 'Terminate on', 'Test_info', 'Test_cases', 'Metrics_method', 'Version']\n",
    "    write_test_results(header_columns, METRICS_FILE)\n",
    "\n",
    "    dt_t = dt.strftime('%H:%M:%S')\n",
    "    noise_info = 'None' if ADD_NOISE == 0 else (1/ADD_NOISE)\n",
    "    header_info = [dt_d, dt_t, ENVIRONMENT_INFO, noise_info, BREAKDOWN_CHANCE, DATA_FILE, env.R1, env.R2, env.R3, WEAR_THRESHOLD, THRESHOLD_FACTOR, EPISODES, MILLING_OPERATIONS_MAX, TEST_INFO, TEST_CASES, METRICS_METHOD, VERSION]\n",
    "    write_test_results(header_info, METRICS_FILE)\n",
    "    write_test_results([], METRICS_FILE) # leave a blank line\n",
    "    print('- Experiment related meta info written.')\n",
    "\n",
    "    df_algo_results = pd.read_csv(RESULTS_FILE)\n",
    "    # algo_metrics = compute_metrics_simple(df_algo_results)\n",
    "    algo_metrics = compute_metrics(df_algo_results)\n",
    "\n",
    "    write_metrics_report(algo_metrics, METRICS_FILE, 4)\n",
    "    write_test_results([], METRICS_FILE) # leave a blank line\n",
    "    print('- Algorithm level consolidated metrics reported to file.')\n",
    "\n",
    "    write_test_results(header_columns, CONSOLIDATED_METRICS_FILE)\n",
    "    write_test_results(header_info, CONSOLIDATED_METRICS_FILE)\n",
    "    write_test_results([], CONSOLIDATED_METRICS_FILE) # leave a blank line\n",
    "    write_metrics_report(algo_metrics, CONSOLIDATED_METRICS_FILE, 4)\n",
    "    write_test_results([120*'-'], CONSOLIDATED_METRICS_FILE) # leave a blank line\n",
    "    print(f'- {CONSOLIDATED_METRICS_FILE} file updated.')\n",
    "    print(algo_metrics.round(3))\n",
    "\n",
    "    # $$$ Update\n",
    "    print(f'- Updating summary performance metrics.')\n",
    "    summary_performance_metrics(df_expts, n_expt, algo_metrics)\n",
    "\n",
    "    print(f'- End Experiment {n_tr_round}-{n_expt}')\n",
    "else:\n",
    "    clean_up_files(RESULTS_FOLDER, VERSION, dt_d, dt_m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
